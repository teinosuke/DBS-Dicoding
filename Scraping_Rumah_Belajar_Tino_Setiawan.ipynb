{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teinosuke/DBS-Dicoding/blob/main/Scraping_Rumah_Belajar_Tino_Setiawan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission DBS Dicoding"
      ],
      "metadata": {
        "id": "-7QCdDrg5D8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proyek Analisis Sentimen"
      ],
      "metadata": {
        "id": "2fDS4rVh5hkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Tino Setiawan\n",
        "\n",
        "---\n",
        "\n",
        "email : tino.setya1@gmail.com"
      ],
      "metadata": {
        "id": "xKepcuUv5k_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pengumpulan Data (Scraping)"
      ],
      "metadata": {
        "id": "NOthTF-P6ZnS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10bdA_d8eiWO",
        "outputId": "c04bd47d-022b-47da-fb06-d32200f43066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m509.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n",
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install google-play-scraper\n",
        "\n",
        "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store.\n",
        "from google_play_scraper import app, reviews, Sort, reviews_all\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import datetime as dt\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "!pip install sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import nltk  # Import Natural Language Toolkit\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store yaitu Ulasan Aplikasi Kihajar STEM.\n",
        "from google_play_scraper import app, reviews_all, Sort\n",
        "\n",
        "# Mengambil semua ulasan dari aplikasi Kihajar STEM dengan ID 'com.kihajar2024' di Google Play Store.\n",
        "scrapreview = reviews_all(\n",
        "    'com.kihajar2024',\n",
        "    lang='id',\n",
        "    country='id',\n",
        "    sort=Sort.MOST_RELEVANT,\n",
        "    count=10000\n",
        ")"
      ],
      "metadata": {
        "id": "Exsd01rnenYq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('review_kihajarstem.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review'])  # Menulis header kolom\n",
        "    for review in scrapreview:\n",
        "        writer.writerow([review['content']])  # Menulis konten review ke dalam file CSV"
      ],
      "metadata": {
        "id": "JaUtrBSagCkK"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}